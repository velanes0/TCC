{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Universidade Estadual de Campinas - Trabalho de Conclusão de Curso \n",
    "## Autor - João Velanes 237824"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parte 1 - Import das bibliotecas a serem utilizadas no projeto "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:34.047404Z",
     "start_time": "2024-08-23T02:41:34.041387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import torch.nn.init as init\n",
    "from torchmetrics import Precision, Recall, Accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:34.103665Z",
     "start_time": "2024-08-23T02:41:34.098440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.197766Z",
     "start_time": "2024-08-23T02:41:34.184344Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"Arquivo Concatenado/falha_2.csv\")\n",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.259869Z",
     "start_time": "2024-08-23T02:41:35.200778Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 655017 entries, 0 to 655016\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   timestamp   655017 non-null  object \n",
      " 1   P-PDG       653476 non-null  float64\n",
      " 2   P-TPT       545968 non-null  float64\n",
      " 3   T-TPT       545968 non-null  float64\n",
      " 4   P-MON-CKP   535750 non-null  float64\n",
      " 5   T-JUS-CKP   486452 non-null  float64\n",
      " 6   P-JUS-CKGL  25668 non-null   float64\n",
      " 7   T-JUS-CKGL  0 non-null       float64\n",
      " 8   QGL         84414 non-null   float64\n",
      " 9   class       594031 non-null  float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 50.0+ MB\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.279585Z",
     "start_time": "2024-08-23T02:41:35.261879Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"class\"].unique()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 102.,   2.,  nan])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.375002Z",
     "start_time": "2024-08-23T02:41:35.281593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1 = df.copy()\n",
    "df1.drop(columns=[\"T-JUS-CKGL\",\"timestamp\"], inplace=True)\n",
    "df1.dropna(inplace=True)\n",
    "df1[\"class\"] = df1[\"class\"].astype(str)\n",
    "df1[\"class\"].replace({\"2.0\":\"1.0\",\"102.0\":\"2.0\"},inplace=True)\n",
    "df1[\"class\"] = df1[\"class\"].astype(float)\n",
    "df1[\"class\"] = df1[\"class\"].astype(int)\n",
    "print(df1[\"class\"].unique())\n",
    "#df1.columns"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.385986Z",
     "start_time": "2024-08-23T02:41:35.379012Z"
    }
   },
   "cell_type": "code",
   "source": "df1.columns",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'P-JUS-CKGL',\n",
       "       'QGL', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.396015Z",
     "start_time": "2024-08-23T02:41:35.387999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Assuming the input is a 1D tensor (e.g., [batch_size, 1, 7] if we treat the feature vector as a single channel)\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1),  # 1D convolution\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Calculate the size after the convolutional layers\n",
    "        self._to_linear = self._calculate_linear_input_size()\n",
    "\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Linear(self._to_linear , num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension: [batch_size, 7] -> [batch_size, 1, 7]\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _calculate_linear_input_size(self):\n",
    "        # Forward pass with a dummy input to calculate the size\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 7)  # Example input size (batch_size, number_of_features)\n",
    "            x = x.unsqueeze(1)  # Adding channel dimension to match Conv1d input\n",
    "            x = self.feature_extractor(x)\n",
    "            return x.shape[1]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.404999Z",
     "start_time": "2024-08-23T02:41:35.398030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classe2(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super(Classe2, self).__init__()\n",
    "        self.data = data.to_numpy(dtype=np.float32) # Usar float 32 por que os pesos da Rede Neural sao Float32\n",
    "        #display(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.data[idx,:-1]\n",
    "        label = int(self.data[idx,-1])\n",
    "        return feature, label"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.418830Z",
     "start_time": "2024-08-23T02:41:35.408007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df1.iloc[:,:-1]\n",
    "y = df1.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.15,random_state=42)"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.438460Z",
     "start_time": "2024-08-23T02:41:35.421838Z"
    }
   },
   "cell_type": "code",
   "source": "y_train.astype(str).value_counts()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    11225\n",
       "2     7874\n",
       "1     2599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.460456Z",
     "start_time": "2024-08-23T02:41:35.440470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming x_train is a pandas DataFrame\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = MaxAbsScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = StandardScaler()\n",
    "# Fit the scaler and transform the data\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame, preserving the column names\n",
    "x_train_scaled_df = pd.DataFrame(x_train_scaled, columns=x_train.columns)\n",
    "\n",
    "# Now x_train_scaled_df is a DataFrame with the same columns as x_train\n",
    "x_train_scaled_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      P-PDG     P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP  P-JUS-CKGL       QGL\n",
       "0  0.000000  0.295903  0.140195   0.448614   1.000000    0.001766  0.000000\n",
       "1  0.000000  0.267060  0.064298   0.282057   1.000000    0.001222  0.000000\n",
       "2  0.989067  0.076469  0.008978   0.000306   0.008113    0.960915  0.284044\n",
       "3  0.000000  0.508781  0.911222   0.585144   0.143568    0.001338  0.000000\n",
       "4  0.000000  1.000000  0.999286   0.999624   1.000000    0.001746  0.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295903</td>\n",
       "      <td>0.140195</td>\n",
       "      <td>0.448614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267060</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>0.282057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989067</td>\n",
       "      <td>0.076469</td>\n",
       "      <td>0.008978</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.960915</td>\n",
       "      <td>0.284044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508781</td>\n",
       "      <td>0.911222</td>\n",
       "      <td>0.585144</td>\n",
       "      <td>0.143568</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:41:35.480997Z",
     "start_time": "2024-08-23T02:41:35.462482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fazendo o feature scaling para os dados teste\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame, preserving the column names\n",
    "x_test_scaled_df = pd.DataFrame(x_test_scaled, columns=x_test.columns)\n",
    "\n",
    "# Now x_train_scaled_df is a DataFrame with the same columns as x_train\n",
    "x_train_scaled_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      P-PDG     P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP  P-JUS-CKGL       QGL\n",
       "0  0.000000  0.295903  0.140195   0.448614   1.000000    0.001766  0.000000\n",
       "1  0.000000  0.267060  0.064298   0.282057   1.000000    0.001222  0.000000\n",
       "2  0.989067  0.076469  0.008978   0.000306   0.008113    0.960915  0.284044\n",
       "3  0.000000  0.508781  0.911222   0.585144   0.143568    0.001338  0.000000\n",
       "4  0.000000  1.000000  0.999286   0.999624   1.000000    0.001746  0.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295903</td>\n",
       "      <td>0.140195</td>\n",
       "      <td>0.448614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267060</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>0.282057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989067</td>\n",
       "      <td>0.076469</td>\n",
       "      <td>0.008978</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.960915</td>\n",
       "      <td>0.284044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508781</td>\n",
       "      <td>0.911222</td>\n",
       "      <td>0.585144</td>\n",
       "      <td>0.143568</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Treinamento do Modelo"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T03:12:27.162404Z",
     "start_time": "2024-08-23T03:01:47.781816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset_train = Classe2(pd.concat([x_train_scaled_df.reset_index(drop=True), # Resetar e dropar index para concatenar corretamente \n",
    "                                   y_train.reset_index(drop=True)], axis=1))\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the neural network, loss function, and optimizer\n",
    "net = Net(3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #0.00001\n",
    "\n",
    "# Initialize metrics\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=3, average=\"weighted\")\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=3, average=\"weighted\")\n",
    "\n",
    "# Loss storage\n",
    "total_loss = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 80\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0  # Initialize epoch loss\n",
    "\n",
    "    # Reset metrics at the beginning of each epoch\n",
    "    metric_precision.reset()\n",
    "    metric_recall.reset()\n",
    "\n",
    "    for features, labels in dataloader_train:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = net(features)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        epoch_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Calculate predictions and update metrics\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        metric_precision.update(preds, labels)\n",
    "        metric_recall.update(preds, labels)\n",
    "        total_loss.append(epoch_loss)\n",
    "    # Compute average loss for the epoch\n",
    "    average_loss = epoch_loss / len(dataloader_train)\n",
    "\n",
    "    # Compute precision and recall for the epoch\n",
    "    precision = metric_precision.compute()\n",
    "    recall = metric_recall.compute()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.6f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Loss: 0.210985, Precision: 0.9245, Recall: 0.9243\n",
      "Epoch [2/80], Loss: 0.116155, Precision: 0.9610, Recall: 0.9601\n",
      "Epoch [3/80], Loss: 0.099841, Precision: 0.9660, Recall: 0.9653\n",
      "Epoch [4/80], Loss: 0.093115, Precision: 0.9700, Recall: 0.9697\n",
      "Epoch [5/80], Loss: 0.085304, Precision: 0.9726, Recall: 0.9723\n",
      "Epoch [6/80], Loss: 0.081393, Precision: 0.9743, Recall: 0.9741\n",
      "Epoch [7/80], Loss: 0.075316, Precision: 0.9766, Recall: 0.9765\n",
      "Epoch [8/80], Loss: 0.073496, Precision: 0.9758, Recall: 0.9757\n",
      "Epoch [9/80], Loss: 0.070888, Precision: 0.9781, Recall: 0.9779\n",
      "Epoch [10/80], Loss: 0.067455, Precision: 0.9779, Recall: 0.9778\n",
      "Epoch [11/80], Loss: 0.064691, Precision: 0.9803, Recall: 0.9802\n",
      "Epoch [12/80], Loss: 0.061893, Precision: 0.9797, Recall: 0.9796\n",
      "Epoch [13/80], Loss: 0.059347, Precision: 0.9806, Recall: 0.9805\n",
      "Epoch [14/80], Loss: 0.058249, Precision: 0.9810, Recall: 0.9808\n",
      "Epoch [15/80], Loss: 0.055490, Precision: 0.9817, Recall: 0.9816\n",
      "Epoch [16/80], Loss: 0.055127, Precision: 0.9821, Recall: 0.9820\n",
      "Epoch [17/80], Loss: 0.054032, Precision: 0.9815, Recall: 0.9814\n",
      "Epoch [18/80], Loss: 0.052234, Precision: 0.9826, Recall: 0.9825\n",
      "Epoch [19/80], Loss: 0.050741, Precision: 0.9833, Recall: 0.9832\n",
      "Epoch [20/80], Loss: 0.050926, Precision: 0.9826, Recall: 0.9825\n",
      "Epoch [21/80], Loss: 0.050137, Precision: 0.9826, Recall: 0.9826\n",
      "Epoch [22/80], Loss: 0.049389, Precision: 0.9830, Recall: 0.9829\n",
      "Epoch [23/80], Loss: 0.046192, Precision: 0.9842, Recall: 0.9841\n",
      "Epoch [24/80], Loss: 0.046231, Precision: 0.9841, Recall: 0.9841\n",
      "Epoch [25/80], Loss: 0.047386, Precision: 0.9835, Recall: 0.9834\n",
      "Epoch [26/80], Loss: 0.042269, Precision: 0.9856, Recall: 0.9855\n",
      "Epoch [27/80], Loss: 0.044294, Precision: 0.9846, Recall: 0.9846\n",
      "Epoch [28/80], Loss: 0.043696, Precision: 0.9848, Recall: 0.9847\n",
      "Epoch [29/80], Loss: 0.043721, Precision: 0.9843, Recall: 0.9842\n",
      "Epoch [30/80], Loss: 0.041006, Precision: 0.9857, Recall: 0.9857\n",
      "Epoch [31/80], Loss: 0.041117, Precision: 0.9850, Recall: 0.9849\n",
      "Epoch [32/80], Loss: 0.041377, Precision: 0.9854, Recall: 0.9853\n",
      "Epoch [33/80], Loss: 0.039361, Precision: 0.9856, Recall: 0.9855\n",
      "Epoch [34/80], Loss: 0.040051, Precision: 0.9861, Recall: 0.9861\n",
      "Epoch [35/80], Loss: 0.040779, Precision: 0.9852, Recall: 0.9851\n",
      "Epoch [36/80], Loss: 0.039137, Precision: 0.9865, Recall: 0.9865\n",
      "Epoch [37/80], Loss: 0.036450, Precision: 0.9872, Recall: 0.9871\n",
      "Epoch [38/80], Loss: 0.037442, Precision: 0.9860, Recall: 0.9860\n",
      "Epoch [39/80], Loss: 0.038425, Precision: 0.9869, Recall: 0.9869\n",
      "Epoch [40/80], Loss: 0.038068, Precision: 0.9865, Recall: 0.9865\n",
      "Epoch [41/80], Loss: 0.037368, Precision: 0.9860, Recall: 0.9860\n",
      "Epoch [42/80], Loss: 0.036857, Precision: 0.9861, Recall: 0.9861\n",
      "Epoch [43/80], Loss: 0.036306, Precision: 0.9863, Recall: 0.9862\n",
      "Epoch [44/80], Loss: 0.034779, Precision: 0.9883, Recall: 0.9882\n",
      "Epoch [45/80], Loss: 0.035248, Precision: 0.9873, Recall: 0.9872\n",
      "Epoch [46/80], Loss: 0.034172, Precision: 0.9878, Recall: 0.9878\n",
      "Epoch [47/80], Loss: 0.033659, Precision: 0.9874, Recall: 0.9874\n",
      "Epoch [48/80], Loss: 0.033650, Precision: 0.9874, Recall: 0.9874\n",
      "Epoch [49/80], Loss: 0.031657, Precision: 0.9887, Recall: 0.9887\n",
      "Epoch [50/80], Loss: 0.037143, Precision: 0.9865, Recall: 0.9865\n",
      "Epoch [51/80], Loss: 0.032563, Precision: 0.9879, Recall: 0.9879\n",
      "Epoch [52/80], Loss: 0.031558, Precision: 0.9882, Recall: 0.9881\n",
      "Epoch [53/80], Loss: 0.033944, Precision: 0.9872, Recall: 0.9872\n",
      "Epoch [54/80], Loss: 0.030664, Precision: 0.9884, Recall: 0.9884\n",
      "Epoch [55/80], Loss: 0.030609, Precision: 0.9887, Recall: 0.9887\n",
      "Epoch [56/80], Loss: 0.031874, Precision: 0.9882, Recall: 0.9882\n",
      "Epoch [57/80], Loss: 0.033571, Precision: 0.9877, Recall: 0.9877\n",
      "Epoch [58/80], Loss: 0.032438, Precision: 0.9881, Recall: 0.9880\n",
      "Epoch [59/80], Loss: 0.028266, Precision: 0.9898, Recall: 0.9898\n",
      "Epoch [60/80], Loss: 0.030600, Precision: 0.9892, Recall: 0.9892\n",
      "Epoch [61/80], Loss: 0.029842, Precision: 0.9885, Recall: 0.9885\n",
      "Epoch [62/80], Loss: 0.030428, Precision: 0.9886, Recall: 0.9886\n",
      "Epoch [63/80], Loss: 0.030585, Precision: 0.9883, Recall: 0.9883\n",
      "Epoch [64/80], Loss: 0.031774, Precision: 0.9890, Recall: 0.9889\n",
      "Epoch [65/80], Loss: 0.030712, Precision: 0.9885, Recall: 0.9885\n",
      "Epoch [66/80], Loss: 0.029709, Precision: 0.9886, Recall: 0.9886\n",
      "Epoch [67/80], Loss: 0.030004, Precision: 0.9887, Recall: 0.9887\n",
      "Epoch [68/80], Loss: 0.028505, Precision: 0.9903, Recall: 0.9902\n",
      "Epoch [69/80], Loss: 0.029102, Precision: 0.9893, Recall: 0.9893\n",
      "Epoch [70/80], Loss: 0.028825, Precision: 0.9889, Recall: 0.9889\n",
      "Epoch [71/80], Loss: 0.028863, Precision: 0.9898, Recall: 0.9898\n",
      "Epoch [72/80], Loss: 0.029114, Precision: 0.9896, Recall: 0.9896\n",
      "Epoch [73/80], Loss: 0.028923, Precision: 0.9889, Recall: 0.9888\n",
      "Epoch [74/80], Loss: 0.028297, Precision: 0.9895, Recall: 0.9894\n",
      "Epoch [75/80], Loss: 0.028387, Precision: 0.9894, Recall: 0.9894\n",
      "Epoch [76/80], Loss: 0.031699, Precision: 0.9894, Recall: 0.9894\n",
      "Epoch [77/80], Loss: 0.028070, Precision: 0.9892, Recall: 0.9892\n",
      "Epoch [78/80], Loss: 0.026748, Precision: 0.9904, Recall: 0.9903\n",
      "Epoch [79/80], Loss: 0.030153, Precision: 0.9893, Recall: 0.9893\n",
      "Epoch [80/80], Loss: 0.027039, Precision: 0.9896, Recall: 0.9895\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T02:57:33.313670Z",
     "start_time": "2024-08-23T02:57:33.054975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchmetrics.classification import Precision, Recall\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming Classe2 and Net are defined elsewhere in your code\n",
    "\n",
    "# Initialize dataset and dataloader for testing\n",
    "dataset_test = Classe2(pd.concat([x_test_scaled_df.reset_index(drop=True),\n",
    "                                  y_test.reset_index(drop=True)], axis=1))\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize metrics for evaluation\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=3, average=None)\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=3, average=None)\n",
    "\n",
    "# Set the network to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "all_labels=[]\n",
    "all_preds=[]\n",
    "# Disable gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    for features, labels in dataloader_test:\n",
    "        outputs = net(features)  # Forward pass\n",
    "        _, preds = torch.max(outputs, dim=1)  # Get predictions\n",
    "\n",
    "        # Update the metrics with predictions and true labels\n",
    "        metric_precision.update(preds, labels)\n",
    "        metric_recall.update(preds, labels)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "# Compute the final precision and recall after processing all batches\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "conf_matrix "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: tensor([0.9919, 0.9142, 0.9766])\n",
      "Recall: tensor([1.0000, 0.9247, 0.9623])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1959,    0,    0],\n",
       "       [   0,  405,   33],\n",
       "       [  16,   38, 1379]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.set_style(\"white\")\n",
    "\n",
    "dados_teste = pd.concat([x_test_scaled_df.reset_index(drop=True),y_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "sns.pairplot(dados_teste, hue=\"class\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
